Before 1949, computers could execute commands, but they could not remember what they did as they were not able to store these commands. In 1950, Alan Turing discussed how to build intelligent machines and test this intelligence in his paper “Computing Machinery and Intelligence.” Five years later, the first AI program was presented at the Dartmouth Summer Research Project on Artificial Intelligence (DSPRAI). This event catalyzed AI research for the next few decades.

Computers became faster, cheaper, and more accessible between 1957 and 1974. Machine learning algorithms improved and, in 1970, one of the hosts of DSPRAI told Life Magazine that there would be a machine with the general intelligence of an average human being in three to eight years. Despite their success, computers’ inability to efficiently store or quickly process information created obstacles in the pursuit of artificial intelligence for the next ten years.

AI was revived in the 1980’s with the expansion of the algorithmic toolkit and more dedicated funds. John Hopefield and David Rumelhart introduced “deep learning” techniques that allowed computers to learn through experience. Edward Feigenbaum introduced “expert systems” that mimicked human decision-making. Despite a lack of government funding and public hype, AI thrived and many landmark goals were achieved in the next two decades. In 1997, reigning chess World Champion and Grandmaster Gary Kasparov was defeated by IBM’s Deep Blue, a chess-playing computer program. The same year, speech recognition software developed by Dragon Systems was implemented on Windows. Cynthia Breazeal also developed Kismet, a robot who could recognize and display emotions.

In 2016, Google’s AlphaGo program beat Go master Lee Se-dol and in 2017, Libratus, a poker-playing supercomputer beat the best human players.